{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "import json\n",
    "import uproot3\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "from coffea import processor, util, hist\n",
    "\n",
    "from plotter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumis = {}\n",
    "lumis['2016'] = 35.9\n",
    "lumis['2017'] = 41.5\n",
    "lumis['2018'] = 59.9\n",
    "\n",
    "with open('xsec.json') as f:\n",
    "  xs = json.load(f)\n",
    "\n",
    "with open('pmap.json') as f:\n",
    "  pmap = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deta_cut = 3.5\n",
    "mjj_cut = 500\n",
    "\n",
    "deta_cut_mucr = 0\n",
    "mjj_cut_mucr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2017'\n",
    "nfiles = len(subprocess.getoutput(\"ls infiles-split/\"+year+\"*.json\").split())\n",
    "outsum = processor.dict_accumulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot add this histogram with histogram <Hist (dataset,region,systematic,pt1,msd1,ddb1,deta,mjj) instance at 0x7fe2c1067a90> of dissimilar dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-222ee7674375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutsum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/accumulator.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    273\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/accumulator.py\u001b[0m in \u001b[0;36m__iadd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/hist/hist_tools.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;34m\"\"\"Add another histogram into this one, in-place\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot add this histogram with histogram %r of dissimilar dimensions\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0mraxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot add this histogram with histogram <Hist (dataset,region,systematic,pt1,msd1,ddb1,deta,mjj) instance at 0x7fe2c1067a90> of dissimilar dimensions"
     ]
    }
   ],
   "source": [
    "# Load all files\n",
    "for n in range(1,nfiles+1):\n",
    "\n",
    "    with open('infiles-split/'+year+'_'+str(n)+'.json') as f:\n",
    "      infiles = json.load(f)\n",
    "    \n",
    "    filename = '/myeosdir/vbf-category/outfiles/'+year+'_'+str(n)+'.coffea'\n",
    "    #filename = 'outfiles/'+year+'_'+str(n)+'.coffea'\n",
    "    if os.path.isfile(filename):\n",
    "        out = util.load(filename)\n",
    "        outsum.add(out)\n",
    "    else:\n",
    "        print(n,infiles.keys())\n",
    "        #print(\"File \" + filename + \" is missing\")\n",
    "        \n",
    "scale_lumi = {k: xs[k] * 1000 *lumis[year] / w for k, w in outsum['sumw'].items()}\n",
    "outsum['templates-vbf'].scale(scale_lumi, 'dataset')\n",
    "outsum['templates-vbf-2'].scale(scale_lumi, 'dataset')\n",
    "\n",
    "templates_vbf = outsum['templates-vbf'].group('dataset', hist.Cat('process', 'Process'), pmap).integrate('region','signal')\n",
    "templates_vbf = templates_vbf.integrate('deta',int_range=slice(deta_cut,7.0)).integrate('mjj',int_range=slice(mjj_cut,4000))\n",
    "templates_vbf.sum('pt1','msd1').integrate('ddb1',int_range=slice(0.89,1)).values()\n",
    "\n",
    "del outsum\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematics = ['nominal',\n",
    "               'jet_triggerUp','jet_triggerDown',\n",
    "               'btagWeightUp','btagWeightDown','btagEffStatUp','btagEffStatDown',\n",
    "               'UESUp','UESDown','JESUp','JESDown','JERUp','JERDown',\n",
    "               'PS_weightUp','PS_weightDown'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = [500,550,600,675,800]\n",
    "\n",
    "for x in split:\n",
    "    for y in split:\n",
    "        if x >= y:\n",
    "            continue\n",
    "        \n",
    "        ptbins = [450, x, y, 1200]\n",
    "        os.system('rm '+year+'/'+str(x)+'_'+str(y)+'/3pt-signalregion.root')\n",
    "        fout = uproot3.create(year+'/3pt-signalregion.root')\n",
    "        for i,b in enumerate(ptbins[:-1]):\n",
    "            for p in pmap.keys(): \n",
    "                if p == \"ttH\" and year == '2016':\n",
    "                    continue\n",
    "            print(p)\n",
    "            if \"data\" in p:\n",
    "                s = \"nominal\"\n",
    "                h = templates_vbf.integrate('systematic',s).integrate('pt1',int_range=slice(ptbins[i],ptbins[i+1])).integrate('ddb1',int_range=slice(0.89,1)).integrate('process',p)\n",
    "                fout[\"pass_pt\"+str(i+1)+\"_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "                h = templates_vbf.integrate('systematic',s).integrate('pt1',int_range=slice(ptbins[i],ptbins[i+1])).integrate('ddb1',int_range=slice(0,0.89)).integrate('process',p)\n",
    "                fout[\"fail_pt\"+str(i+1)+\"_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "            else:\n",
    "                for s in systematics:\n",
    "                    h = templates_vbf.integrate('systematic',s).integrate('pt1',int_range=slice(ptbins[i],ptbins[i+1])).integrate('ddb1',int_range=slice(0.89,1)).integrate('process',p)\n",
    "                    fout[\"pass_pt\"+str(i+1)+\"_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "                    h = templates_vbf.integrate('systematic',s).integrate('pt1',int_range=slice(ptbins[i],ptbins[i+1])).integrate('ddb1',int_range=slice(0,0.89)).integrate('process',p)\n",
    "                    fout[\"fail_pt\"+str(i+1)+\"_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "\n",
    "        fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('rm '+year+'/muonCR.root')\n",
    "fout = uproot3.create(year+'/muonCR.root')\n",
    "for p in pmap.keys():  \n",
    "    if p == 'ttH' and year == '2016':\n",
    "        continue\n",
    "    print(p)\n",
    "    if \"data\" in p:\n",
    "        s = \"nominal\"\n",
    "        h = templates_vbf_mucr.integrate('systematic',s).sum('pt1').integrate('ddb1',int_range=slice(0.89,1)).integrate('process',p)\n",
    "        fout[\"pass_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "        h = templates_vbf_mucr.integrate('systematic',s).sum('pt1').integrate('ddb1',int_range=slice(0,0.89)).integrate('process',p)\n",
    "        fout[\"fail_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "    else:\n",
    "        for s in systematics:\n",
    "            h = templates_vbf_mucr.integrate('systematic',s).sum('pt1').integrate('ddb1',int_range=slice(0.89,1)).integrate('process',p)\n",
    "            fout[\"pass_\"+p+\"_\"+s] = hist.export1d(h)\n",
    "            h = templates_vbf_mucr.integrate('systematic',s).sum('pt1').integrate('ddb1',int_range=slice(0,0.89)).integrate('process',p)\n",
    "            fout[\"fail_\"+p+\"_\"+s] = hist.export1d(h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
