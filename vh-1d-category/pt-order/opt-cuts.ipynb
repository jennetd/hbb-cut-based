{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "import json\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "from coffea import processor, util, hist\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "\n",
    "import mplhep as hep\n",
    "plt.style.use([hep.style.ROOT, hep.style.CMS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {}\n",
    "colors['QCD'] = '#1f77b4'\n",
    "colors['VBF'] = '#ff7f0e'\n",
    "colors['VV'] = '#2ca02c'\n",
    "colors['Wjets'] = '#d62728'\n",
    "colors['WH'] = '#9467bd'\n",
    "colors['Zjets'] = '#8c564b'\n",
    "colors['ZH'] = '#e377c2'\n",
    "colors['ggF'] = '#7f7f7f'\n",
    "colors['ttbar'] = '#bcdb22'\n",
    "colors['singlet'] = '#bcdb22'\n",
    "colors['ttH'] = '#17becf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumis = {}\n",
    "lumis['2016'] = 35.9\n",
    "lumis['2017'] = 41.5\n",
    "lumis['2018'] = 59.9\n",
    "\n",
    "nfiles_mc = {}\n",
    "nfiles_mc['2016'] = 64\n",
    "nfiles_mc['2017'] = 89\n",
    "nfiles_mc['2018'] = 106\n",
    "\n",
    "with open('xsec.json') as f:\n",
    "  xs = json.load(f)\n",
    "\n",
    "with open('pmap.json') as f:\n",
    "  pmap = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2018'\n",
    "outsum = processor.dict_accumulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higgs mass window\n",
    "mbb_min = 110\n",
    "mbb_max = 138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(s,b):\n",
    "    if b==0:\n",
    "        return 0\n",
    "    z_squared = 2.0*(s+b)*np.log(1.0+1.0*s/b) - 2.0*s\n",
    "    return np.sqrt(z_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overlay(x,name):\n",
    "    x.label = 'Events'\n",
    "    axes = hist.plotgrid(x, overlay='process', line_opts={}, order=['QCD','Zjets','Wjets','ttbar','singlet','VV','ggF','VBF','WH','ZH','ttH'])\n",
    "    axes[0, 0].set_prop_cycle(cycler(color=colors.values()))\n",
    "    axes[0, 0].set_yscale('log')\n",
    "    axes[0, 0].set_ylim(.001, 100000)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    fig_name = year+'/plot-all/'+name+'.png'\n",
    "    plt.savefig(fig_name,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stack(x,name):\n",
    "    x.label = 'Events'\n",
    "    axes = hist.plot1d(x, overlay='process', fill_opts={'edgecolor': (0,0,0,1)}, stack=True, order=['ttH','ZH','WH','VBF','ggF','VV','ttbar','singlet','Wjets','Zjets','QCD'])\n",
    "    axes.set_prop_cycle(cycler(color=colors.values()))\n",
    "    axes.set_yscale('log')\n",
    "    axes.set_ylim(.001, 100000)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    fig_name = year+'/plot-all/'+name+'_stack.png'\n",
    "    plt.savefig(fig_name,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_plot(sr, name):\n",
    "    \n",
    "    nggF_sel = sr[('ggF',)]\n",
    "    nVBF_sel = sr[('VBF',)]\n",
    "    nWH_sel = sr[('WH',)]\n",
    "    nZH_sel = sr[('ZH',)]\n",
    "    nttH_sel = sr[('ttH',)]\n",
    "    \n",
    "    nQCD_sel = sr[('QCD',)]\n",
    "    nVV_sel = sr[('VV'),]\n",
    "    nWjets_sel = sr[('Wjets',)]\n",
    "    nZjets_sel = sr[('Zjets',)]\n",
    "    nttbar_sel = sr[('ttbar',)]\n",
    "    nst_sel = sr[('singlet',)]\n",
    "\n",
    "    sr_name = name+'-like'\n",
    "    categories = [sr_name]\n",
    "    \n",
    "    yields = {}\n",
    "    yields['ttH'] = [nttH_sel]\n",
    "    yields['ZH'] = [nZH_sel]\n",
    "    yields['WH'] = [nWH_sel]\n",
    "    yields['VBF'] = [nVBF_sel]\n",
    "    yields['ggF'] = [nggF_sel]\n",
    "               \n",
    "    yields['VV'] = [nVV_sel]\n",
    "    yields['ttbar'] = [nttbar_sel]\n",
    "    yields['singlet'] = [nst_sel]\n",
    "    yields['Wjets'] = [nWjets_sel]\n",
    "    yields['Zjets'] = [nZjets_sel]\n",
    "    yields['QCD'] = [nQCD_sel]\n",
    "    \n",
    "    with open(year+'/plot-all/'+name+'_yield.json', 'w') as outfile:\n",
    "        json.dump(yields, outfile)\n",
    "    \n",
    "    print(yields)\n",
    "    \n",
    "    y = [0]\n",
    "    for p in ['ttH','ZH','WH','VBF','ggF','VV','Wjets','Zjets','QCD','ttbar','singlet']:\n",
    "        bars = y\n",
    "        if p == 'ttH':\n",
    "            plt.bar(categories, yields[p], width=1, color=colors[p], label=p)\n",
    "        else:\n",
    "            plt.bar(categories, yields[p], width=1, color=colors[p], bottom=bars, label=p)\n",
    "            \n",
    "        y = [y[0]+yields[p][0]]\n",
    "\n",
    "    plt.ylabel('Events')\n",
    "    plt.yscale('log')\n",
    "    plt.ylim(0.1,100000)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    fig_name = year+'/plot-all/'+name+'_yield.png'\n",
    "    plt.savefig(fig_name,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "File condor/outfiles/2018_1.coffea is missing\n",
      "2\n",
      "File condor/outfiles/2018_2.coffea is missing\n",
      "3\n",
      "File condor/outfiles/2018_3.coffea is missing\n",
      "4\n",
      "File condor/outfiles/2018_4.coffea is missing\n",
      "5\n",
      "File condor/outfiles/2018_5.coffea is missing\n",
      "6\n",
      "File condor/outfiles/2018_6.coffea is missing\n",
      "7\n",
      "File condor/outfiles/2018_7.coffea is missing\n",
      "8\n",
      "File condor/outfiles/2018_8.coffea is missing\n",
      "9\n",
      "File condor/outfiles/2018_9.coffea is missing\n",
      "10\n",
      "File condor/outfiles/2018_10.coffea is missing\n",
      "11\n",
      "File condor/outfiles/2018_11.coffea is missing\n",
      "12\n",
      "File condor/outfiles/2018_12.coffea is missing\n",
      "13\n",
      "File condor/outfiles/2018_13.coffea is missing\n",
      "14\n",
      "File condor/outfiles/2018_14.coffea is missing\n",
      "15\n",
      "File condor/outfiles/2018_15.coffea is missing\n",
      "16\n",
      "File condor/outfiles/2018_16.coffea is missing\n",
      "17\n",
      "File condor/outfiles/2018_17.coffea is missing\n",
      "18\n",
      "File condor/outfiles/2018_18.coffea is missing\n",
      "19\n",
      "File condor/outfiles/2018_19.coffea is missing\n",
      "20\n",
      "File condor/outfiles/2018_20.coffea is missing\n",
      "21\n",
      "File condor/outfiles/2018_21.coffea is missing\n",
      "22\n",
      "File condor/outfiles/2018_22.coffea is missing\n",
      "23\n",
      "File condor/outfiles/2018_23.coffea is missing\n",
      "24\n",
      "File condor/outfiles/2018_24.coffea is missing\n",
      "25\n",
      "File condor/outfiles/2018_25.coffea is missing\n",
      "26\n",
      "File condor/outfiles/2018_26.coffea is missing\n",
      "27\n",
      "File condor/outfiles/2018_27.coffea is missing\n",
      "28\n",
      "File condor/outfiles/2018_28.coffea is missing\n",
      "29\n",
      "File condor/outfiles/2018_29.coffea is missing\n",
      "30\n",
      "File condor/outfiles/2018_30.coffea is missing\n",
      "31\n",
      "File condor/outfiles/2018_31.coffea is missing\n",
      "32\n",
      "File condor/outfiles/2018_32.coffea is missing\n",
      "33\n",
      "File condor/outfiles/2018_33.coffea is missing\n",
      "34\n",
      "File condor/outfiles/2018_34.coffea is missing\n",
      "35\n",
      "File condor/outfiles/2018_35.coffea is missing\n",
      "36\n",
      "File condor/outfiles/2018_36.coffea is missing\n",
      "37\n",
      "File condor/outfiles/2018_37.coffea is missing\n",
      "38\n",
      "File condor/outfiles/2018_38.coffea is missing\n",
      "39\n",
      "File condor/outfiles/2018_39.coffea is missing\n",
      "40\n",
      "File condor/outfiles/2018_40.coffea is missing\n",
      "41\n",
      "File condor/outfiles/2018_41.coffea is missing\n",
      "42\n",
      "File condor/outfiles/2018_42.coffea is missing\n",
      "43\n",
      "File condor/outfiles/2018_43.coffea is missing\n",
      "44\n",
      "File condor/outfiles/2018_44.coffea is missing\n",
      "45\n",
      "File condor/outfiles/2018_45.coffea is missing\n",
      "46\n",
      "File condor/outfiles/2018_46.coffea is missing\n",
      "47\n",
      "File condor/outfiles/2018_47.coffea is missing\n",
      "48\n",
      "File condor/outfiles/2018_48.coffea is missing\n",
      "49\n",
      "File condor/outfiles/2018_49.coffea is missing\n",
      "50\n",
      "File condor/outfiles/2018_50.coffea is missing\n",
      "51\n",
      "File condor/outfiles/2018_51.coffea is missing\n",
      "52\n",
      "File condor/outfiles/2018_52.coffea is missing\n",
      "53\n",
      "File condor/outfiles/2018_53.coffea is missing\n",
      "54\n",
      "File condor/outfiles/2018_54.coffea is missing\n",
      "55\n",
      "File condor/outfiles/2018_55.coffea is missing\n",
      "56\n",
      "File condor/outfiles/2018_56.coffea is missing\n",
      "57\n",
      "File condor/outfiles/2018_57.coffea is missing\n",
      "58\n",
      "File condor/outfiles/2018_58.coffea is missing\n",
      "59\n",
      "File condor/outfiles/2018_59.coffea is missing\n",
      "60\n",
      "File condor/outfiles/2018_60.coffea is missing\n",
      "61\n",
      "File condor/outfiles/2018_61.coffea is missing\n",
      "62\n",
      "File condor/outfiles/2018_62.coffea is missing\n",
      "63\n",
      "File condor/outfiles/2018_63.coffea is missing\n",
      "64\n",
      "File condor/outfiles/2018_64.coffea is missing\n",
      "65\n",
      "File condor/outfiles/2018_65.coffea is missing\n",
      "66\n",
      "File condor/outfiles/2018_66.coffea is missing\n",
      "67\n",
      "File condor/outfiles/2018_67.coffea is missing\n",
      "68\n",
      "File condor/outfiles/2018_68.coffea is missing\n",
      "69\n",
      "File condor/outfiles/2018_69.coffea is missing\n",
      "70\n",
      "File condor/outfiles/2018_70.coffea is missing\n",
      "71\n",
      "File condor/outfiles/2018_71.coffea is missing\n",
      "72\n",
      "File condor/outfiles/2018_72.coffea is missing\n",
      "73\n",
      "File condor/outfiles/2018_73.coffea is missing\n",
      "74\n",
      "File condor/outfiles/2018_74.coffea is missing\n",
      "75\n",
      "File condor/outfiles/2018_75.coffea is missing\n",
      "76\n",
      "File condor/outfiles/2018_76.coffea is missing\n",
      "77\n",
      "File condor/outfiles/2018_77.coffea is missing\n",
      "78\n",
      "File condor/outfiles/2018_78.coffea is missing\n",
      "79\n",
      "File condor/outfiles/2018_79.coffea is missing\n",
      "80\n",
      "File condor/outfiles/2018_80.coffea is missing\n",
      "81\n",
      "File condor/outfiles/2018_81.coffea is missing\n",
      "82\n",
      "File condor/outfiles/2018_82.coffea is missing\n",
      "83\n",
      "File condor/outfiles/2018_83.coffea is missing\n",
      "84\n",
      "File condor/outfiles/2018_84.coffea is missing\n",
      "85\n",
      "File condor/outfiles/2018_85.coffea is missing\n",
      "86\n",
      "File condor/outfiles/2018_86.coffea is missing\n",
      "87\n",
      "File condor/outfiles/2018_87.coffea is missing\n",
      "88\n",
      "File condor/outfiles/2018_88.coffea is missing\n",
      "89\n",
      "File condor/outfiles/2018_89.coffea is missing\n",
      "90\n",
      "File condor/outfiles/2018_90.coffea is missing\n",
      "91\n",
      "File condor/outfiles/2018_91.coffea is missing\n",
      "92\n",
      "File condor/outfiles/2018_92.coffea is missing\n",
      "93\n",
      "File condor/outfiles/2018_93.coffea is missing\n",
      "94\n",
      "File condor/outfiles/2018_94.coffea is missing\n",
      "95\n",
      "File condor/outfiles/2018_95.coffea is missing\n",
      "96\n",
      "File condor/outfiles/2018_96.coffea is missing\n",
      "97\n",
      "File condor/outfiles/2018_97.coffea is missing\n",
      "98\n",
      "File condor/outfiles/2018_98.coffea is missing\n",
      "99\n",
      "File condor/outfiles/2018_99.coffea is missing\n",
      "100\n",
      "File condor/outfiles/2018_100.coffea is missing\n",
      "101\n",
      "File condor/outfiles/2018_101.coffea is missing\n",
      "102\n",
      "File condor/outfiles/2018_102.coffea is missing\n",
      "103\n",
      "File condor/outfiles/2018_103.coffea is missing\n",
      "104\n",
      "File condor/outfiles/2018_104.coffea is missing\n",
      "105\n",
      "File condor/outfiles/2018_105.coffea is missing\n",
      "106\n",
      "File condor/outfiles/2018_106.coffea is missing\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sumw'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5e6a41b4f226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is missing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mscale_lumi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlumis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sumw'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0moutsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'templates-pt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale_lumi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sumw'"
     ]
    }
   ],
   "source": [
    "# Load all MC\n",
    "for n in range(1,nfiles_mc[year]+1):\n",
    "    print(n)\n",
    "    filename = 'condor/outfiles/'+year+'_'+str(n)+'.coffea'\n",
    "    if os.path.isfile(filename):\n",
    "        out = util.load(filename)\n",
    "        outsum.add(out)\n",
    "    else:\n",
    "        print(\"File \" + filename + \" is missing\")\n",
    "        \n",
    "scale_lumi = {k: xs[k] * 1000 *lumis[year] / w for k, w in outsum['sumw'].items()}\n",
    "outsum['templates-pt'].scale(scale_lumi, 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates0 = outsum['templates-pt'].integrate('region', 'signal')\n",
    "del outsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = templates0.group('dataset', hist.Cat('process', 'Process'), pmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = templates.sum('msd1','msd2','n2ddt2').integrate('ddb1',int_range=slice(0.89,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overlay(x,'pt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stack(x,'pt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = templates.sum('pt2', 'n2ddt2', 'msd1').integrate('ddb1',int_range=slice(0.89,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overlay(x,'msd2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stack(x,'msd2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = templates.sum('pt2','msd2','msd1').integrate('ddb1',int_range=slice(0.89,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overlay(x,'n2ddt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stack(x,'n2ddt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = templates.integrate('msd1',int_range=slice(mbb_min, mbb_max)).integrate('ddb1',int_range=slice(0.89,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if year == '2017':\n",
    "\n",
    "    cuts3 = []\n",
    "    sigs3 = []\n",
    "\n",
    "    msd2_slices = [i*7+40 for i in range(1,23)]\n",
    "    for msd2_min in msd2_slices:\n",
    "        for msd2_max in msd2_slices:\n",
    "            if msd2_max <= msd2_min:\n",
    "                continue\n",
    "\n",
    "            sliced = x.sum('pt2','n2ddt2').integrate('msd2',int_range=slice(msd2_min,msd2_max))\n",
    "            s = sliced.values()[('ZH',)] + sliced.values()[('WH',)]\n",
    "            b = sliced.values()[('ggF',)] + sliced.values()[('VBF',)] + sliced.values()[('ttH',)] \n",
    "            b += sliced.values()[('QCD',)] + sliced.values()[('Wjets',)] + sliced.values()[('Zjets',)] + sliced.values()[('VV',)] + sliced.values()[('ttbar',)] + sliced.values()[('singlet',)]\n",
    "            \n",
    "            sigs3 += [significance(s,b)]\n",
    "            cuts3 += [[msd2_min,msd2_max]]\n",
    "        \n",
    "    cuts3 = np.array(cuts3)\n",
    "    print(max(sigs3))\n",
    "    print(cuts3[np.argmax(sigs3)])\n",
    "\n",
    "    msd_min_vh = cuts3[np.argmax(sigs3)][0]\n",
    "    msd_max_vh = cuts3[np.argmax(sigs3)][1]\n",
    "\n",
    "    plt.hist2d(cuts3[:,0], cuts3[:,1], density=False, weights=sigs3, bins=[21,21]);\n",
    "    plt.xlabel('$msd_{min}$');\n",
    "    plt.ylabel('$msd_{max}$');\n",
    "    plt.savefig(year+'/plot-all/vh_2d_msdminmax.png')\n",
    "    \n",
    "else:\n",
    "    msd2_min = 75\n",
    "    msd2_max = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if year == '2017':\n",
    "\n",
    "    cuts5 = []\n",
    "    sigs5 = []\n",
    "\n",
    "    pt2_slices = [300, 350, 400, 450, 500, 550, 600, 675, 800]\n",
    "    n2ddt2_slices = [-0.25+0.25*i for i in range(1,3)]\n",
    "\n",
    "    for pt2 in pt2_slices:\n",
    "        for n2ddt2 in n2ddt2_slices:\n",
    "\n",
    "            msd2_min = msd_min_vh\n",
    "            msd2_max = msd_max_vh\n",
    "        \n",
    "            sliced = x.integrate('msd2',int_range=slice(msd2_min,msd2_max)).integrate('pt2',int_range=slice(pt2,1200)).integrate('n2ddt2',int_range=slice(-0.25,n2ddt2))\n",
    "        \n",
    "            s = sliced.values()[('ZH',)] + sliced.values()[('WH',)]\n",
    "            b = sliced.values()[('ggF',)] + sliced.values()[('VBF',)] + sliced.values()[('ttH',)] \n",
    "            b += sliced.values()[('QCD',)] + sliced.values()[('Wjets',)] + sliced.values()[('Zjets',)] + sliced.values()[('VV',)] + sliced.values()[('ttbar',)] + sliced.values()[('singlet',)]\n",
    "            \n",
    "            sigs5 += [significance(s,b)]\n",
    "            cuts5 += [[pt2,n2ddt2]]\n",
    "        \n",
    "    cuts5 = np.array(cuts5)\n",
    "    print(max(sigs5))\n",
    "    print(cuts5[np.argmax(sigs5)])\n",
    "\n",
    "    n2ddt2_cut = cuts5[np.argmax(sigs5)][1]\n",
    "    pt2_cut = cuts5[np.argmax(sigs5)][0]\n",
    "\n",
    "    plt.hist2d(cuts5[:,0], cuts5[:,1], density=False, weights=sigs5, bins=[[300, 350, 400, 450, 500, 550, 600, 675, 800, 1200],[0,0.25,0.5]]);\n",
    "    plt.xlabel('$p_{T}$');\n",
    "    plt.ylabel('n2ddt');\n",
    "    plt.savefig(year+'/plot-all/vh_2d_n2ddtpt.png')\n",
    "    \n",
    "else:\n",
    "    pt2_cut = 550\n",
    "    n2ddt2_cut = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = x.integrate('msd2',int_range=slice(msd2_min,msd2_max)).integrate('n2ddt2',int_range=slice(-0.25,n2ddt2_cut)).integrate('pt2',int_range=slice(pt2_cut,1200)).values()\n",
    "yield_plot(sr, 'vh-bkgopt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significance\n",
    "s = sr[('WH',)] + sr[('ZH',)]\n",
    "b = sr[('QCD',)] + sr[('Zjets',)] + sr[('Wjets',)]  + sr[('VV',)] + sr[('ttbar',)] +sr[('singlet',)] + sr[('ggF',)] + sr[('VBF',)] + sr[('ttH',)]\n",
    "\n",
    "print(s,b)\n",
    "print(significance(s,b))\n",
    "\n",
    "# this only makes sense in the mass window of Higgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhist = templates.integrate('ddb1',int_range=slice(0.89,1)).integrate('msd2',int_range=slice(msd2_min,msd2_max)).integrate('n2ddt2',int_range=slice(-0.25,n2ddt2_cut)).integrate('pt2',int_range=slice(pt2_cut,1200))\n",
    "plot_stack(mhist,'vh-msd1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(index=['$V$ jet $m_{sd}$','$V$ jet N2DDT','$V$ jet $p_T$','$H$ jet DeepDoubleB'],columns=['ggF','VBF','WH','ZH','ttH'])\n",
    "df2 = pd.DataFrame(index=['$V$ jet $m_{sd}$','$V$ jet N2DDT','$V$ jet $p_T$','$H$ jet DeepDoubleB'],columns=['QCD','Wjets','Zjets','VV','ttbar','singlet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msd2 cut\n",
    "tmp = templates.sum('msd1','pt2','n2ddt2','ddb1').integrate('msd2',int_range=slice(msd2_min,msd2_max)).values()\n",
    "cutname = '$V$ jet $m_{sd}$'\n",
    "\n",
    "df1['ggF'][cutname] = tmp[('ggF'),]\n",
    "df1['VBF'][cutname] = tmp[('VBF'),]\n",
    "df1['WH'][cutname] = tmp[('WH'),]\n",
    "df1['ZH'][cutname] = tmp[('ZH'),]\n",
    "df1['ttH'][cutname] = tmp[('ttH'),]\n",
    "\n",
    "df2['QCD'][cutname] = tmp[('QCD'),]\n",
    "df2['Wjets'][cutname] = tmp[('Wjets'),]\n",
    "df2['Zjets'][cutname] = tmp[('Zjets'),]\n",
    "df2['VV'][cutname] = tmp[('VV'),]\n",
    "df2['ttbar'][cutname] = tmp[('ttbar'),]\n",
    "df2['singlet'][cutname] = tmp[('singlet'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n2ddt2\n",
    "tmp = templates.sum('msd1','pt2','ddb1').integrate('msd2',int_range=slice(msd2_min,msd2_max)).integrate('n2ddt2',int_range=slice(-0.25,n2ddt2_cut)).values()\n",
    "cutname = '$V$ jet N2DDT'\n",
    "\n",
    "df1['ggF'][cutname] = tmp[('ggF'),]\n",
    "df1['VBF'][cutname] = tmp[('VBF'),]\n",
    "df1['WH'][cutname] = tmp[('WH'),]\n",
    "df1['ZH'][cutname] = tmp[('ZH'),]\n",
    "df1['ttH'][cutname] = tmp[('ttH'),]\n",
    "\n",
    "df2['QCD'][cutname] = tmp[('QCD'),]\n",
    "df2['Wjets'][cutname] = tmp[('Wjets'),]\n",
    "df2['Zjets'][cutname] = tmp[('Zjets'),]\n",
    "df2['VV'][cutname] = tmp[('VV'),]\n",
    "df2['ttbar'][cutname] = tmp[('ttbar'),]\n",
    "df2['singlet'][cutname] = tmp[('singlet'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt2\n",
    "tmp = templates.sum('msd1','ddb1').integrate('msd2',int_range=slice(msd2_min,msd2_max)).integrate('n2ddt2',int_range=slice(-0.25,n2ddt2_cut)).integrate('pt2',int_range=slice(pt2_cut,1200)).values()\n",
    "cutname = '$V$ jet $p_T$'\n",
    "\n",
    "df1['ggF'][cutname] = tmp[('ggF'),]\n",
    "df1['VBF'][cutname] = tmp[('VBF'),]\n",
    "df1['WH'][cutname] = tmp[('WH'),]\n",
    "df1['ZH'][cutname] = tmp[('ZH'),]\n",
    "df1['ttH'][cutname] = tmp[('ttH'),]\n",
    "\n",
    "df2['QCD'][cutname] = tmp[('QCD'),]\n",
    "df2['Wjets'][cutname] = tmp[('Wjets'),]\n",
    "df2['Zjets'][cutname] = tmp[('Zjets'),]\n",
    "df2['VV'][cutname] = tmp[('VV'),]\n",
    "df2['ttbar'][cutname] = tmp[('ttbar'),]\n",
    "df2['singlet'][cutname] = tmp[('singlet'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ddb1\n",
    "tmp = templates.sum('msd1').integrate('msd2',int_range=slice(msd2_min,msd2_max)).integrate('n2ddt2',int_range=slice(-0.25,n2ddt2_cut)).integrate('pt2',int_range=slice(pt2_cut,1200)).integrate('ddb1',int_range=slice(0.89,1)).values()\n",
    "cutname = '$H$ jet DeepDoubleB'\n",
    "\n",
    "df1['ggF'][cutname] = tmp[('ggF'),]\n",
    "df1['VBF'][cutname] = tmp[('VBF'),]\n",
    "df1['WH'][cutname] = tmp[('WH'),]\n",
    "df1['ZH'][cutname] = tmp[('ZH'),]\n",
    "df1['ttH'][cutname] = tmp[('ttH'),]\n",
    "\n",
    "df2['QCD'][cutname] = tmp[('QCD'),]\n",
    "df2['Wjets'][cutname] = tmp[('Wjets'),]\n",
    "df2['Zjets'][cutname] = tmp[('Zjets'),]\n",
    "df2['VV'][cutname] = tmp[('VV'),]\n",
    "df2['ttbar'][cutname] = tmp[('ttbar'),]\n",
    "df2['singlet'][cutname] = tmp[('singlet'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1)\n",
    "df1 = df1.astype('int')\n",
    "df1.to_latex(buf=year+'/cutflow-sig.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2)\n",
    "df2 = df2.astype('int')\n",
    "df2.to_latex(buf=year+'/cutflow-bkg.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard-coded -- combine results from all 3 years\n",
    "\n",
    "VH = 0\n",
    "tot_H = 0\n",
    "\n",
    "#2016\n",
    "VH += 0.576513 + 0.335428\n",
    "tot_H += 0.00495358 + 0.0620203 + 0.576513 + 0.335428 + 0.0373796\n",
    "\n",
    "#2017\n",
    "VH += 1.62591 + 1.05862\n",
    "tot_H += 0.223702 + 0.245804 + 1.62591 + 1.05862 + 0.159492\n",
    "\n",
    "#2018\n",
    "VH += 0.957751 + 0.626182\n",
    "tot_H += 0.0775505 + 0.0235961 + 0.957751 + 0.626182 + 0.0504347\n",
    "\n",
    "print(VH/tot_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(.115**2 + .181**2 + .196**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
