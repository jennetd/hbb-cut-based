{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "import json\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "from coffea import processor, util, hist\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {}\n",
    "colors['QCD'] = '#1f77b4'\n",
    "colors['VBF'] = '#ff7f0e'\n",
    "colors['VV'] = '#2ca02c'\n",
    "colors['Wjets'] = '#d62728'\n",
    "colors['WH'] = '#9467bd'\n",
    "colors['Zjets'] = '#8c564b'\n",
    "colors['ZH'] = '#e377c2'\n",
    "colors['ggF'] = '#7f7f7f'\n",
    "colors['ttbar'] = '#bcdb22'\n",
    "colors['singlet'] = '#bcdb22'\n",
    "colors['ttH'] = '#17becf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumis = {}\n",
    "lumis['2016'] = 35.9\n",
    "lumis['2017'] = 41.5\n",
    "lumis['2018'] = 59.9\n",
    "\n",
    "nfiles_mc = {}\n",
    "nfiles_mc['2016'] = 64\n",
    "nfiles_mc['2017'] = 89\n",
    "nfiles_mc['2018'] = 106\n",
    "\n",
    "with open('xsec.json') as f:\n",
    "  xs = json.load(f)\n",
    "\n",
    "with open('pmap.json') as f:\n",
    "  pmap = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2018'\n",
    "outsum = processor.dict_accumulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higgs mass window\n",
    "mbb_min = 110\n",
    "mbb_max = 138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significance(s,b):\n",
    "    if b==0:\n",
    "        return 0\n",
    "    z_squared = 2.0*(s+b)*np.log(1.0+1.0*s/b) - 2.0*s\n",
    "    return np.sqrt(z_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overlay(x,name):\n",
    "    x.label = 'Events'\n",
    "    axes = hist.plotgrid(x, overlay='process', line_opts={}, order=['QCD','Zjets','Wjets','ttbar','singlet','VV','ggF','VBF','WH','ZH','ttH'])\n",
    "    axes[0, 0].set_prop_cycle(cycler(color=colors.values()))\n",
    "    axes[0, 0].set_yscale('log')\n",
    "    axes[0, 0].set_ylim(.001, 100000)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    fig_name = year+'/plot-all/'+name+'.png'\n",
    "    plt.savefig(fig_name,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stack(x,name):\n",
    "    x.label = 'Events'\n",
    "    axes = hist.plot1d(x, overlay='process', fill_opts={'edgecolor': (0,0,0,1)}, stack=True, order=['ttH','ZH','WH','VBF','ggF','VV','ttbar','singlet','Wjets','Zjets','QCD'])\n",
    "    axes.set_prop_cycle(cycler(color=colors.values()))\n",
    "    axes.set_yscale('log')\n",
    "    axes.set_ylim(.001, 100000)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    fig_name = year+'/plot-all/'+name+'_stack.png'\n",
    "    plt.savefig(fig_name,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_plot(sr, name):\n",
    "    \n",
    "    nggF_sel = sr[('ggF',)]\n",
    "    nVBF_sel = sr[('VBF',)]\n",
    "    nWH_sel = sr[('WH',)]\n",
    "    nZH_sel = sr[('ZH',)]\n",
    "    nttH_sel = sr[('ttH',)]\n",
    "    \n",
    "    nQCD_sel = sr[('QCD',)]\n",
    "    nVV_sel = sr[('VV'),]\n",
    "    nWjets_sel = sr[('Wjets',)]\n",
    "    nZjets_sel = sr[('Zjets',)]\n",
    "    nttbar_sel = sr[('ttbar',)]\n",
    "    nst_sel = sr[('singlet',)]\n",
    "\n",
    "    sr_name = name+'-like'\n",
    "    categories = [sr_name]\n",
    "    \n",
    "    yields = {}\n",
    "    yields['ttH'] = [nttH_sel]\n",
    "    yields['ZH'] = [nZH_sel]\n",
    "    yields['WH'] = [nWH_sel]\n",
    "    yields['VBF'] = [nVBF_sel]\n",
    "    yields['ggF'] = [nggF_sel]\n",
    "               \n",
    "    yields['VV'] = [nVV_sel]\n",
    "    yields['ttbar'] = [nttbar_sel]\n",
    "    yields['singlet'] = [nst_sel]\n",
    "    yields['Wjets'] = [nWjets_sel]\n",
    "    yields['Zjets'] = [nZjets_sel]\n",
    "    yields['QCD'] = [nQCD_sel]\n",
    "    \n",
    "    with open(year+'/plot-all/'+name+'_yield.json', 'w') as outfile:\n",
    "        json.dump(yields, outfile)\n",
    "    \n",
    "    print(yields)\n",
    "    \n",
    "    y = [0]\n",
    "    for p in ['ttH','ZH','WH','VBF','ggF','VV','Wjets','Zjets','QCD','ttbar','singlet']:\n",
    "        bars = y\n",
    "        if p == 'ttH':\n",
    "            plt.bar(categories, yields[p], width=1, color=colors[p], label=p)\n",
    "        else:\n",
    "            plt.bar(categories, yields[p], width=1, color=colors[p], bottom=bars, label=p)\n",
    "            \n",
    "        y = [y[0]+yields[p][0]]\n",
    "\n",
    "    plt.ylabel('Events')\n",
    "    plt.yscale('log')\n",
    "    plt.ylim(0.1,100000)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    fig_name = year+'/plot-all/'+name+'_yield.png'\n",
    "    plt.savefig(fig_name,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot add this histogram with histogram <Hist (dataset,region,pt1,msd1,ddb1,pt2,msd2,ddb2,n2ddt2) instance at 0x7f2996c1b518> of dissimilar dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-245-db21cdf4ce49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutsum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is missing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/coffea/processor/accumulator.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    140\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/coffea/processor/accumulator.py\u001b[0m in \u001b[0;36m__iadd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/coffea/hist/hist_tools.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;34m\"\"\"Add another histogram into this one, in-place\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot add this histogram with histogram %r of dissimilar dimensions\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mraxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot add this histogram with histogram <Hist (dataset,region,pt1,msd1,ddb1,pt2,msd2,ddb2,n2ddt2) instance at 0x7f2996c1b518> of dissimilar dimensions"
     ]
    }
   ],
   "source": [
    "# Load all MC\n",
    "for n in range(1,nfiles_mc[year]+1):\n",
    "    print(n)\n",
    "    filename = 'condor/outfiles/'+year+'_'+str(n)+'.coffea'\n",
    "    if os.path.isfile(filename):\n",
    "        out = util.load(filename)\n",
    "        outsum.add(out)\n",
    "    else:\n",
    "        print(\"File \" + filename + \" is missing\")\n",
    "        \n",
    "scale_lumi = {k: xs[k] * 1000 *lumis[year] / w for k, w in outsum['sumw'].items()}\n",
    "outsum['templates-m'].scale(scale_lumi, 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates0 = outsum['templates-m'].integrate('region', 'signal')\n",
    "del outsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = templates0.group('dataset', hist.Cat('process', 'Process'), pmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = templates.sum('msd1','msd2','n2ddt2').integrate('ddb1',int_range=slice(0.89,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overlay(x,'pt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stack(x,'pt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = templates.sum('pt2', 'n2ddt2', 'msd1').integrate('ddb1',int_range=slice(0.89,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overlay(x,'msd2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stack(x,'msd2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = templates.sum('pt2','msd2','msd1').integrate('ddb1',int_range=slice(0.89,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overlay(x,'n2ddt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stack(x,'n2ddt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = templates.integrate('msd1',int_range=slice(mbb_min, mbb_max)).integrate('ddb1',int_range=slice(0.89,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if year == '2017':\n",
    "\n",
    "    cuts3 = []\n",
    "    sigs3 = []\n",
    "\n",
    "    msd2_slices = [i*7+40 for i in range(1,23)]\n",
    "    for msd2_min in msd2_slices:\n",
    "        for msd2_max in msd2_slices:\n",
    "            if msd2_max <= msd2_min:\n",
    "                continue\n",
    "\n",
    "            sliced = x.sum('pt2','n2ddt2').integrate('msd2',int_range=slice(msd2_min,msd2_max))\n",
    "            s = sliced.values()[('ZH',)] + sliced.values()[('WH',)]\n",
    "            b = sliced.values()[('ggF',)] + sliced.values()[('VBF',)] + sliced.values()[('ttH',)] \n",
    "            b += sliced.values()[('QCD',)] + sliced.values()[('Wjets',)] + sliced.values()[('Zjets',)] + sliced.values()[('VV',)] + sliced.values()[('ttbar',)] + sliced.values()[('singlet',)]\n",
    "            \n",
    "            sigs3 += [significance(s,b)]\n",
    "            cuts3 += [[msd2_min,msd2_max]]\n",
    "        \n",
    "    cuts3 = np.array(cuts3)\n",
    "    print(max(sigs3))\n",
    "    print(cuts3[np.argmax(sigs3)])\n",
    "\n",
    "    msd_min_vh = cuts3[np.argmax(sigs3)][0]\n",
    "    msd_max_vh = cuts3[np.argmax(sigs3)][1]\n",
    "\n",
    "    plt.hist2d(cuts3[:,0], cuts3[:,1], density=False, weights=sigs3, bins=[21,21]);\n",
    "    plt.xlabel('$msd_{min}$');\n",
    "    plt.ylabel('$msd_{max}$');\n",
    "    plt.savefig(year+'/plot-all/vh_2d_msdminmax.png')\n",
    "    \n",
    "else:\n",
    "    msd2_min = 68\n",
    "    msd2_max = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if year == '2017':\n",
    "\n",
    "    cuts5 = []\n",
    "    sigs5 = []\n",
    "\n",
    "    pt2_slices = [300, 350, 400, 450, 500, 550, 600, 675, 800]\n",
    "    n2ddt2_slices = [-0.25+0.25*i for i in range(1,3)]\n",
    "\n",
    "    for pt2 in pt2_slices:\n",
    "        for n2ddt2 in n2ddt2_slices:\n",
    "\n",
    "            msd2_min = msd_min_vh\n",
    "            msd2_max = msd_max_vh\n",
    "        \n",
    "            sliced = x.integrate('msd2',int_range=slice(msd2_min,msd2_max)).integrate('pt2',int_range=slice(pt2,1200)).integrate('n2ddt2',int_range=slice(-0.25,n2ddt2))\n",
    "        \n",
    "            s = sliced.values()[('ZH',)] + sliced.values()[('WH',)]\n",
    "            b = sliced.values()[('ggF',)] + sliced.values()[('VBF',)] + sliced.values()[('ttH',)] \n",
    "            b += sliced.values()[('QCD',)] + sliced.values()[('Wjets',)] + sliced.values()[('Zjets',)] + sliced.values()[('VV',)] + sliced.values()[('ttbar',)] + sliced.values()[('singlet',)]\n",
    "            \n",
    "            sigs5 += [significance(s,b)]\n",
    "            cuts5 += [[pt2,n2ddt2]]\n",
    "        \n",
    "    cuts5 = np.array(cuts5)\n",
    "    print(max(sigs5))\n",
    "    print(cuts5[np.argmax(sigs5)])\n",
    "\n",
    "    n2ddt2_cut = cuts5[np.argmax(sigs5)][1]\n",
    "    pt2_cut = cuts5[np.argmax(sigs5)][0]\n",
    "\n",
    "    plt.hist2d(cuts5[:,0], cuts5[:,1], density=False, weights=sigs5, bins=[[300, 350, 400, 450, 500, 550, 600, 675, 800,1200],[0,0.25,0.5]]);\n",
    "    plt.xlabel('$p_{T}$');\n",
    "    plt.ylabel('n2ddt');\n",
    "    plt.savefig(year+'/plot-all/vh_2d_n2ddtpt.png')\n",
    "    \n",
    "else:\n",
    "    pt2_cut = 550\n",
    "    n2ddt2_cut = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = x.integrate('msd2',int_range=slice(msd2_min,msd2_max)).integrate('n2ddt2',int_range=slice(-0.25,n2ddt2_cut)).integrate('pt2',int_range=slice(pt2_cut,1200)).values()\n",
    "yield_plot(sr, 'vh-bkgopt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significance\n",
    "s = sr[('WH',)] + sr[('ZH',)]\n",
    "b = sr[('QCD',)] + sr[('Zjets',)] + sr[('Wjets',)]  + sr[('VV',)] + sr[('ttbar',)] +sr[('singlet',)] + sr[('ggF',)] + sr[('VBF',)] + sr[('ttH',)]\n",
    "\n",
    "print(s,b)\n",
    "print(significance(s,b))\n",
    "\n",
    "# this only makes sense in the mass window of Higgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhist = templates.integrate('ddb1',int_range=slice(0.89,1)).integrate('msd2',int_range=slice(msd2_min,msd2_max)).integrate('n2ddt2',int_range=slice(-0.25,n2ddt2_cut)).integrate('pt2',int_range=slice(pt2_cut,1200))\n",
    "plot_stack(mhist,'vh-msd1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
